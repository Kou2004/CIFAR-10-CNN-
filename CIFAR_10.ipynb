{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8UqMPtZRcwTmhgXMONGvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kou2004/CIFAR-10-CNN-/blob/main/CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout,Flatten,BatchNormalization,Conv2D,MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Preprocess and augment the training data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Load the DenseNet-121 model with pretrained weights\n",
        "#base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Create a Sequential model\n",
        "#model = Sequential()\n",
        "\n",
        "# Add the DenseNet-121 model as the base\n",
        "#model.add(base_model)\n",
        "\n",
        "# Add custom classification head with dropout layers\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(1024, activation='relu'))\n",
        "#model.add(Dropout(0.6))\n",
        "#model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "#for layer in base_model.layers:\n",
        "   # layer.trainable = False\n",
        "\n",
        "# Learning rate schedule\n",
        "#def lr_schedule(epoch):\n",
        "    #if epoch < 5:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dtsP_tA4AxF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (32, 32, 3)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "# Pooling layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Dropout layers\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=256, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "kE9A8303lBm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    if epoch < 15:\n",
        "        return 0.001\n",
        "    if epoch < 30:\n",
        "        return 0.0001\n",
        "    return 0.00001\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation and learning rate scheduling\n",
        "batch_size = 100\n",
        "epochs = 30\n",
        "model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(x_train) / batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMu9TQzmlpDf",
        "outputId": "ee12a131-4f75-437a-faff-911e6e49b934"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "500/500 [==============================] - 44s 70ms/step - loss: 2.1388 - accuracy: 0.2087 - val_loss: 3.3427 - val_accuracy: 0.1723 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.7798 - accuracy: 0.3287 - val_loss: 1.6972 - val_accuracy: 0.3792 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 1.6212 - accuracy: 0.3974 - val_loss: 1.9390 - val_accuracy: 0.3728 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.4873 - accuracy: 0.4691 - val_loss: 1.1949 - val_accuracy: 0.5749 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.3494 - accuracy: 0.5271 - val_loss: 1.1167 - val_accuracy: 0.6047 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 1.2467 - accuracy: 0.5677 - val_loss: 1.3599 - val_accuracy: 0.5589 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 1.1697 - accuracy: 0.5968 - val_loss: 1.3417 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 1.1089 - accuracy: 0.6212 - val_loss: 1.0025 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 1.0373 - accuracy: 0.6473 - val_loss: 0.8123 - val_accuracy: 0.7206 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 1.0018 - accuracy: 0.6628 - val_loss: 1.0257 - val_accuracy: 0.6703 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.9628 - accuracy: 0.6751 - val_loss: 0.9655 - val_accuracy: 0.6787 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.9311 - accuracy: 0.6856 - val_loss: 1.0088 - val_accuracy: 0.6458 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.9060 - accuracy: 0.6942 - val_loss: 0.9353 - val_accuracy: 0.6942 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 0.8829 - accuracy: 0.7046 - val_loss: 0.7802 - val_accuracy: 0.7382 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.8604 - accuracy: 0.7112 - val_loss: 0.8947 - val_accuracy: 0.7077 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.7921 - accuracy: 0.7329 - val_loss: 0.7086 - val_accuracy: 0.7633 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.7652 - accuracy: 0.7443 - val_loss: 0.6694 - val_accuracy: 0.7749 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.7513 - accuracy: 0.7491 - val_loss: 0.7026 - val_accuracy: 0.7653 - lr: 1.0000e-04\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 0.7404 - accuracy: 0.7502 - val_loss: 0.6724 - val_accuracy: 0.7754 - lr: 1.0000e-04\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.7351 - accuracy: 0.7525 - val_loss: 0.6603 - val_accuracy: 0.7821 - lr: 1.0000e-04\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.7306 - accuracy: 0.7541 - val_loss: 0.7103 - val_accuracy: 0.7631 - lr: 1.0000e-04\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.7340 - accuracy: 0.7563 - val_loss: 0.6443 - val_accuracy: 0.7842 - lr: 1.0000e-04\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.7189 - accuracy: 0.7582 - val_loss: 0.6555 - val_accuracy: 0.7783 - lr: 1.0000e-04\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 0.7161 - accuracy: 0.7616 - val_loss: 0.6239 - val_accuracy: 0.7902 - lr: 1.0000e-04\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.7085 - accuracy: 0.7624 - val_loss: 0.6587 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 0.7135 - accuracy: 0.7611 - val_loss: 0.6521 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 0.7069 - accuracy: 0.7602 - val_loss: 0.6431 - val_accuracy: 0.7820 - lr: 1.0000e-04\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.7051 - accuracy: 0.7614 - val_loss: 0.6429 - val_accuracy: 0.7806 - lr: 1.0000e-04\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.6989 - accuracy: 0.7639 - val_loss: 0.5822 - val_accuracy: 0.8038 - lr: 1.0000e-04\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 0.6895 - accuracy: 0.7676 - val_loss: 0.6170 - val_accuracy: 0.7925 - lr: 1.0000e-04\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.7925\n",
            "Test Accuracy: 79.25%\n"
          ]
        }
      ]
    }
  ]
}